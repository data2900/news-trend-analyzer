# extract_keywords.py

import pandas as pd
from pathlib import Path
from datetime import datetime
from janome.tokenizer import Tokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter
import re
import sys

# === ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿è¨­å®šï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›´ï¼‰===
BASE_DIR = Path(__file__).resolve().parent.parent / "news"
date_str = datetime.now().strftime("%Y%m%d")
INPUT_CSV = BASE_DIR / "output" / f"news_{date_str}.csv"

if not INPUT_CSV.exists():
    sys.exit(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {INPUT_CSV}")

print(f"ğŸ“‚ ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {INPUT_CSV.name}")

# === å½¢æ…‹ç´ è§£æå™¨ã®åˆæœŸåŒ–ï¼ˆåè©ã®ã¿ï¼‰===
tokenizer = Tokenizer()

def tokenize(text):
    words = []
    for token in tokenizer.tokenize(text):
        base = token.base_form
        pos = token.part_of_speech.split(',')[0]
        if pos == 'åè©' and len(base) > 1 and not re.match(r'^[\dï¼-ï¼™]+$', base):
            words.append(base)
    return words

# === CSVèª­ã¿è¾¼ã¿ï¼ˆã‚¿ã‚¤ãƒˆãƒ«åˆ—ã®ã¿ä½¿ç”¨ï¼‰===
df = pd.read_csv(INPUT_CSV, usecols=["ã‚¿ã‚¤ãƒˆãƒ«"])
df = df.dropna(subset=["ã‚¿ã‚¤ãƒˆãƒ«"])
texts = df["ã‚¿ã‚¤ãƒˆãƒ«"].tolist()

# === TFï¼ˆå˜èªã®å‡ºç¾é »åº¦ï¼‰ ===
all_words = []
for title in texts:
    all_words.extend(tokenize(title))

tf_counts = Counter(all_words)
print("\nğŸ“Š ä¸Šä½TFï¼ˆé »å‡ºèªï¼‰:")
for word, freq in tf_counts.most_common(20):
    print(f"{word}: {freq}")

# === TF-IDFï¼ˆé‡è¦èªï¼‰ ===
def analyzer(text):
    return tokenize(text)

vectorizer = TfidfVectorizer(analyzer=analyzer, use_idf=True, smooth_idf=True)
X = vectorizer.fit_transform(texts)
scores = zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0))
sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)

print("\nğŸ’¡ ä¸Šä½TF-IDFï¼ˆé‡è¦èªï¼‰:")
for word, score in sorted_scores[:20]:
    print(f"{word}: {score:.4f}")

# ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¿å­˜
top_words = [word for word, _ in tf_counts.most_common(10)]
with open(BASE_DIR / "output" / "top_keywords.txt", "w", encoding="utf-8") as f:
    for word in top_words:
        f.write(f"{word}\n")

print("\nâœ… ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆtop_keywords.txtï¼‰")